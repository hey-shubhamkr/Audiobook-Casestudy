{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"Audiobooks_data.csv\", delimiter = \",\")\n",
    "\n",
    "all_inputs = data[:,1:-1]\n",
    "all_targets = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_target = int(np.sum(all_targets))\n",
    "\n",
    "num_zero_target = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(all_targets.shape[0]):\n",
    "    if all_targets[i]==0:\n",
    "        num_zero_target +=1\n",
    "        if num_zero_target > num_one_target:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "balanced_unscaled_input = np.delete(all_inputs, indices_to_remove, axis=0)\n",
    "balanced_unscaled_target = np.delete(all_targets, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(balanced_unscaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = balanced_unscaled_target[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = shuffled_data.shape[0]\n",
    "\n",
    "num_train_data = int(0.8* count)\n",
    "num_validation_data = int(0.1 * count)\n",
    "num_test_data = (count-num_train_data - num_validation_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = shuffled_data[:num_train_data]\n",
    "train_target = shuffled_targets[:num_train_data]\n",
    "\n",
    "validation_input = shuffled_data[num_train_data:num_train_data+ num_validation_data]\n",
    "validation_target = shuffled_targets[num_train_data : num_train_data+num_validation_data]\n",
    "\n",
    "test_input = shuffled_data[num_train_data+num_validation_data:]\n",
    "test_target = shuffled_targets[num_train_data+num_validation_data:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to check the splitting, we'll divide the the number of targets having 1 by total no. of targets which should come around 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784.0 3579 0.4984632578932663\n",
      "238.0 447 0.5324384787472034\n",
      "215.0 3579 0.4984632578932663\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_target), num_train_data , np.sum(train_target/num_train_data))\n",
    "print(np.sum(validation_target), num_validation_data , np.sum(validation_target/num_validation_data))\n",
    "print(np.sum(test_target), num_train_data , np.sum(train_target/num_train_data))\n",
    "\n",
    "#we can see that the number of training dataset is clearly larger and that the data is balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"Audio_data_train\", input = train_input, output = train_target)\n",
    "np.savez(\"Audio_data_validation\", input = validation_input, output = validation_target)\n",
    "np.savez(\"Audio_data_test\", input = test_input, output = test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
